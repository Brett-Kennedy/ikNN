{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3bb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df104b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from time import perf_counter\n",
    "from statistics import stdev, mean\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from interpretable_knn import interpretable_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2911786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sklearn's decision tree using either the original or the original plus the generated features\n",
    "def test_classification(X, y):\n",
    "    \n",
    "    def test_sklearn_knn():    \n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "        t1 = perf_counter()\n",
    "        scores = cross_validate(clf, X, y, cv=5, scoring='f1_macro', return_train_score=True)\n",
    "        t2 = perf_counter()\n",
    "        #print(f\"Cross Validated sklearn KNeighbors Classifier in {t2 - t1:0.4f} seconds\")\n",
    "        return scores\n",
    "    \n",
    "    def test_2d_knn(visualize_2d_spaces=False):       \n",
    "        clf = interpretable_knn()\n",
    "        t1 = perf_counter()\n",
    "        scores = cross_validate(clf, X, y, cv=5, scoring='f1_macro', return_train_score=True)\n",
    "        t2 = perf_counter()\n",
    "        #print(f\"Cross Validated interpretable_knn in {t2 - t1:0.4f} seconds\")\n",
    "    \n",
    "        if visualize_2d_spaces:\n",
    "            # Create a single interpretable_knn to use for visualization\n",
    "            clf_final = interpretable_knn(n_neighbors=5, method=method, weight_by_score=weight_by_score, num_best_spaces=num_best_spaces)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            y_test=y_test.values\n",
    "            clf_final.fit(X_train, y_train)        \n",
    "            pred_y_train = clf_final.predict(X_train)\n",
    "            pred_y_test = clf_final.predict(X_test)\n",
    "            #print(\"pred_y_test: \", pred_y_test)\n",
    "            #print(\"y_test: \", y_test)\n",
    "            #print(\"len(pred_y_test): \", len(pred_y_test))\n",
    "            #print(\"len(y_test): \", len(y_test))\n",
    "            wrong_rows = []\n",
    "            for i in range(len(y_test)):\n",
    "                #print(\"str(pred_y_test[i]): \", str(list(pred_y_test)[i]))\n",
    "                #print(\"str(y_test[i]): \", str(list(y_test)[i]))\n",
    "                if (str(pred_y_test[i]) != str(y_test[i])):\n",
    "                    wrong_rows.append(i)\n",
    "            print(\"wrong_rows: \", wrong_rows)\n",
    "\n",
    "            #for i in range(len(X_test)):\n",
    "            for i in range(5):\n",
    "                clf_final.graph_2d_spaces(X_test.iloc[i], i, y_test[i:i+1][0])\n",
    "            \n",
    "        return scores\n",
    "    \n",
    "    def print_scores(scores):    \n",
    "        train_scores = scores['train_score']\n",
    "        test_scores = scores['test_score']\n",
    "        avg_train_score = mean(train_scores)\n",
    "        avg_test_score = mean(test_scores)\n",
    "        scores_std_dev = stdev(test_scores)\n",
    "\n",
    "        print(\"\\nAverage f1 score on training data: \", round(avg_train_score,3))\n",
    "        print(\"Average f1 score on test data: \", round(avg_test_score,3))\n",
    "        print(\"Std dev of f1 scores on test data: \", round(scores_std_dev,3))\n",
    "        \n",
    "    print_scores(test_sklearn_knn(hyperparams_setting='default'))\n",
    "    print_scores(test_2d_knn(hyperparams_setting='default', visualize_2d_spaces=False))\n",
    "    print_scores(test_sklearn_knn(hyperparams_setting='grid_search'))\n",
    "    print_scores(test_2d_knn(hyperparams_setting='grid_search', visualize_2d_spaces=False))\n",
    "\n",
    "# Given a method to load a dataset, load the dataset and test the accuracy of a sklearn decision tree with and without\n",
    "# the extended features.\n",
    "def test_dataset(X, y, file_name):\n",
    "    print(\"\\n\\n*********************************************\")\n",
    "    print(\"Calling for \" + file_name)\n",
    "    print(\"*********************************************\")\n",
    "    \n",
    "    # One-hot encode any non-numeric columns\n",
    "    is_numeric_arr = []\n",
    "    for c in range(len(X.columns)):\n",
    "        if is_numeric_dtype(X[X.columns[c]]):\n",
    "            is_numeric_arr.append(1)\n",
    "        else:\n",
    "            is_numeric_arr.append(0)    \n",
    "    new_df = pd.DataFrame()\n",
    "    for c in range(len(is_numeric_arr)):\n",
    "        col_name = X.columns[c]\n",
    "        if is_numeric_arr[c] == 0:\n",
    "            one_hot_cols = pd.get_dummies(X[col_name], prefix=col_name, dummy_na=True, drop_first=False)\n",
    "            new_df = pd.concat([new_df, one_hot_cols], axis=1)\n",
    "            #num_one_hot_cols = len(one_hot_cols.columns)\n",
    "        else:\n",
    "            new_df[col_name] = X[col_name]\n",
    "    X = new_df\n",
    "    \n",
    "    X = X.fillna(0.0)\n",
    "    X = X.replace([np.inf, -np.inf], 0.0)                \n",
    "    print(\"shape: \", X.shape)\n",
    "    \n",
    "    test_classification(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51dc4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test datasets from public sources\n",
    "# todo: any that don't work well, remove. Need to run overnight still.\n",
    "\n",
    "def test_public_dataset(filename, drop_cols, target_col, problem_type):\n",
    "    file_df = pd.read_csv(\"TestData/\" + filename)\n",
    "    file_df = file_df.drop(drop_cols, axis = 1)\n",
    "    X = file_df.drop([target_col], axis = 1)\n",
    "    y = file_df[target_col].astype(str)\n",
    "    test_dataset(X, y, filename)\n",
    "\n",
    "def test_schooling():\n",
    "    # From https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Schooling.html\n",
    "    # Removed lwage76 as it's the log of wage76. Used wage76 as the target, though created a new\n",
    "    # column for this called low_wage, which is 1 when wage76 is < 1000\n",
    "    test_public_dataset(\"schooling.csv\", ['lwage76','wage76'], \"low_wage\", \"classification\")\n",
    "\n",
    "def test_spam7():  \n",
    "    # From: http://vincentarelbundock.github.io/Rdatasets/doc/DAAG/spam7.html\n",
    "    test_public_dataset(\"spam7.csv\", [], \"yesno\", \"classification\")\n",
    "\n",
    "def test_creditcardcsvpresent():\n",
    "    # From: https://www.kaggle.com/shubhamjoshi2130of/abstract-data-set-for-credit-card-fraud-detection\n",
    "    test_public_dataset(\"creditcardcsvpresent.csv\", [], \"isFradulent\", \"classification\")\n",
    "\n",
    "def test_wilt():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Wilt\n",
    "    test_public_dataset(\"wilt_training.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_QSAR_biodegredation():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation#\n",
    "    test_public_dataset(\"biodeg.csv\", [], \"experimental class\", \"classification\")\n",
    "\n",
    "def test_statlog():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Statlog+%28Image+Segmentation%29\n",
    "    test_public_dataset(\"statlog.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_segmentation():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Image+Segmentation\n",
    "    test_public_dataset(\"Segmentation.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_frogs():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29#\n",
    "    # It's possible to predict Family, Genus, or Species\n",
    "    test_public_dataset(\"Frogs_MFCCs.csv\", [], \"Family\", \"classification\")\n",
    "\n",
    "def test_blocks():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Page+Blocks+Classification\n",
    "    test_public_dataset(\"page_block.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_electrical_grid():\n",
    "    # From https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "    test_public_dataset(\"electrical_grid.csv\", ['stab'], \"stabf\", \"classification\")\n",
    "\n",
    "def test_bank8FM():\n",
    "    # From https://www.openml.org/d/725\n",
    "    test_public_dataset(\"bank8FM.csv\", [], \"binaryClass\", \"classification\")\n",
    "\n",
    "def test_eeg_eye_state():\n",
    "    # From https://www.openml.org/d/1471\n",
    "    test_public_dataset(\"eeg-eye-state.csv\", [], \"Class\", \"classification\")\n",
    "\n",
    "def test_vowel():\n",
    "    # From https://www.openml.org/d/307\n",
    "    test_public_dataset(\"vowel.csv\", [], \"Class\", \"classification\")\n",
    "\n",
    "def test_vehicle():\n",
    "    # From https://www.openml.org/d/994\n",
    "    test_public_dataset(\"vehicle.csv\", [], \"binaryClass\", \"classification\")\n",
    "\n",
    "def test_space_ga():\n",
    "    # From https://www.openml.org/d/722\n",
    "    test_public_dataset(\"space_ga.csv\", [], \"binaryClass\", \"classification\")\n",
    "\n",
    "def test_pol():\n",
    "    # From https://www.openml.org/d/737\n",
    "    test_public_dataset(\"pol.csv\", [], \"binaryClass\", \"classification\")\n",
    "\n",
    "def test_ringnorm():\n",
    "    # From https://www.openml.org/d/1496\n",
    "    test_public_dataset(\"ringnorm.csv\", [], \"Class\", \"classification\")\n",
    "\n",
    "def test_churn():\n",
    "    # From https://www.openml.org/d/40701\n",
    "    test_public_dataset(\"churn.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_biomed():\n",
    "    # From https://www.openml.org/d/481\n",
    "    test_public_dataset(\"biomed.csv\", [], \"class\", \"classification\")\n",
    "\n",
    "def test_kdd_el_nino_small():\n",
    "    # From https://www.openml.org/d/839\n",
    "    test_public_dataset(\"kdd_el_nino-small.csv\", [], \"binaryClass\", \"classification\")\n",
    "\n",
    "def test_artificial_characters():\n",
    "    # From https://www.openml.org/d/1459\n",
    "    test_public_dataset(\"artificial-characters.csv\", [], \"Class\", \"classification\")\n",
    "\n",
    "def test_fri_c3_500_25():\n",
    "    # From https://www.openml.org/d/896\n",
    "    test_public_dataset(\"fri_c3_500_25.csv\", [], \"binaryClass\", \"classification\")\n",
    "     \n",
    "def test_public_datasets():    \n",
    "    # For faster execution time, comment out any of the functions below not necessary\n",
    "\n",
    "    # Test files from http://vincentarelbundock.github.io/Rdatasets/\n",
    "    test_schooling()    \n",
    "    test_spam7()\n",
    "\n",
    "    # Test files from Kaggle\n",
    "    test_creditcardcsvpresent()\n",
    "\n",
    "    # Test files from UCI\n",
    "    test_wilt()\n",
    "    test_QSAR_biodegredation()\n",
    "    test_statlog()\n",
    "    test_segmentation()\n",
    "    test_frogs()\n",
    "    test_blocks()\n",
    "    test_electrical_grid()\n",
    "\n",
    "    # Test files from OpenML\n",
    "    test_bank8FM()\n",
    "    test_eeg_eye_state()\n",
    "    test_vowel()\n",
    "    test_vehicle()\n",
    "    test_space_ga() \n",
    "    test_pol()\n",
    "    test_ringnorm()\n",
    "    test_churn()\n",
    "    test_biomed()\n",
    "    test_kdd_el_nino_small()\n",
    "    test_artificial_characters()\n",
    "    test_fri_c3_500_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332da8a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for schooling.csv\n",
      "*********************************************\n",
      "shape:  (3010, 65)\n",
      "\n",
      "Average f1 score on training data:  0.634\n",
      "Average f1 score on test data:  0.263\n",
      "Std dev of f1 scores on test data:  0.14\n",
      "\n",
      "Average f1 score on training data:  0.646\n",
      "Average f1 score on test data:  0.58\n",
      "Std dev of f1 scores on test data:  0.047\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for spam7.csv\n",
      "*********************************************\n",
      "shape:  (4601, 7)\n",
      "\n",
      "Average f1 score on training data:  0.999\n",
      "Average f1 score on test data:  0.895\n",
      "Std dev of f1 scores on test data:  0.148\n",
      "\n",
      "Average f1 score on training data:  1.0\n",
      "Average f1 score on test data:  0.892\n",
      "Std dev of f1 scores on test data:  0.15\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for creditcardcsvpresent.csv\n",
      "*********************************************\n",
      "shape:  (3075, 17)\n",
      "\n",
      "Average f1 score on training data:  0.643\n",
      "Average f1 score on test data:  0.345\n",
      "Std dev of f1 scores on test data:  0.119\n",
      "\n",
      "Average f1 score on training data:  0.827\n",
      "Average f1 score on test data:  0.828\n",
      "Std dev of f1 scores on test data:  0.037\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for wilt_training.csv\n",
      "*********************************************\n",
      "shape:  (4339, 5)\n",
      "\n",
      "Average f1 score on training data:  0.877\n",
      "Average f1 score on test data:  0.825\n",
      "Std dev of f1 scores on test data:  0.09\n",
      "\n",
      "Average f1 score on training data:  0.506\n",
      "Average f1 score on test data:  0.496\n",
      "Std dev of f1 scores on test data:  0.0\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for biodeg.csv\n",
      "*********************************************\n",
      "shape:  (1055, 41)\n",
      "\n",
      "Average f1 score on training data:  0.856\n",
      "Average f1 score on test data:  0.79\n",
      "Std dev of f1 scores on test data:  0.069\n",
      "\n",
      "Average f1 score on training data:  0.861\n",
      "Average f1 score on test data:  0.709\n",
      "Std dev of f1 scores on test data:  0.046\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for statlog.csv\n",
      "*********************************************\n",
      "shape:  (2310, 19)\n",
      "\n",
      "Average f1 score on training data:  0.968\n",
      "Average f1 score on test data:  0.939\n",
      "Std dev of f1 scores on test data:  0.015\n",
      "\n",
      "Average f1 score on training data:  0.947\n",
      "Average f1 score on test data:  0.85\n",
      "Std dev of f1 scores on test data:  0.018\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for Segmentation.csv\n",
      "*********************************************\n",
      "shape:  (2100, 19)\n",
      "\n",
      "Average f1 score on training data:  0.961\n",
      "Average f1 score on test data:  0.89\n",
      "Std dev of f1 scores on test data:  0.045\n",
      "\n",
      "Average f1 score on training data:  0.936\n",
      "Average f1 score on test data:  0.775\n",
      "Std dev of f1 scores on test data:  0.068\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for Frogs_MFCCs.csv\n",
      "*********************************************\n",
      "shape:  (7195, 43)\n",
      "\n",
      "Average f1 score on training data:  1.0\n",
      "Average f1 score on test data:  0.836\n",
      "Std dev of f1 scores on test data:  0.225\n",
      "\n",
      "Average f1 score on training data:  1.0\n",
      "Average f1 score on test data:  0.793\n",
      "Std dev of f1 scores on test data:  0.295\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for page_block.csv\n",
      "*********************************************\n",
      "shape:  (5473, 10)\n",
      "\n",
      "Average f1 score on training data:  0.812\n",
      "Average f1 score on test data:  0.625\n",
      "Std dev of f1 scores on test data:  0.086\n",
      "\n",
      "Average f1 score on training data:  0.829\n",
      "Average f1 score on test data:  0.597\n",
      "Std dev of f1 scores on test data:  0.086\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for electrical_grid.csv\n",
      "*********************************************\n",
      "shape:  (10000, 12)\n",
      "\n",
      "Average f1 score on training data:  0.845\n",
      "Average f1 score on test data:  0.759\n",
      "Std dev of f1 scores on test data:  0.007\n",
      "\n",
      "Average f1 score on training data:  0.882\n",
      "Average f1 score on test data:  0.615\n",
      "Std dev of f1 scores on test data:  0.005\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for bank8FM.csv\n",
      "*********************************************\n",
      "shape:  (8192, 8)\n",
      "\n",
      "Average f1 score on training data:  0.948\n",
      "Average f1 score on test data:  0.928\n",
      "Std dev of f1 scores on test data:  0.004\n",
      "\n",
      "Average f1 score on training data:  0.937\n",
      "Average f1 score on test data:  0.773\n",
      "Std dev of f1 scores on test data:  0.013\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for eeg-eye-state.csv\n",
      "*********************************************\n",
      "shape:  (14980, 14)\n",
      "\n",
      "Average f1 score on training data:  0.989\n",
      "Average f1 score on test data:  0.468\n",
      "Std dev of f1 scores on test data:  0.086\n",
      "\n",
      "Average f1 score on training data:  0.783\n",
      "Average f1 score on test data:  0.42\n",
      "Std dev of f1 scores on test data:  0.086\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for vowel.csv\n",
      "*********************************************\n",
      "shape:  (990, 29)\n",
      "\n",
      "Average f1 score on training data:  0.989\n",
      "Average f1 score on test data:  0.578\n",
      "Std dev of f1 scores on test data:  0.052\n",
      "\n",
      "Average f1 score on training data:  0.893\n",
      "Average f1 score on test data:  0.405\n",
      "Std dev of f1 scores on test data:  0.057\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for vehicle.csv\n",
      "*********************************************\n",
      "shape:  (846, 18)\n",
      "\n",
      "Average f1 score on training data:  0.922\n",
      "Average f1 score on test data:  0.869\n",
      "Std dev of f1 scores on test data:  0.029\n",
      "\n",
      "Average f1 score on training data:  0.917\n",
      "Average f1 score on test data:  0.84\n",
      "Std dev of f1 scores on test data:  0.041\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for space_ga.csv\n",
      "*********************************************\n",
      "shape:  (3107, 6)\n",
      "\n",
      "Average f1 score on training data:  0.746\n",
      "Average f1 score on test data:  0.495\n",
      "Std dev of f1 scores on test data:  0.038\n",
      "\n",
      "Average f1 score on training data:  0.872\n",
      "Average f1 score on test data:  0.713\n",
      "Std dev of f1 scores on test data:  0.063\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for pol.csv\n",
      "*********************************************\n",
      "shape:  (15000, 48)\n",
      "\n",
      "Average f1 score on training data:  0.978\n",
      "Average f1 score on test data:  0.966\n",
      "Std dev of f1 scores on test data:  0.003\n",
      "\n",
      "Average f1 score on training data:  0.828\n",
      "Average f1 score on test data:  0.784\n",
      "Std dev of f1 scores on test data:  0.006\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for ringnorm.csv\n",
      "*********************************************\n",
      "shape:  (7400, 20)\n",
      "\n",
      "Average f1 score on training data:  0.732\n",
      "Average f1 score on test data:  0.646\n",
      "Std dev of f1 scores on test data:  0.004\n",
      "\n",
      "Average f1 score on training data:  0.876\n",
      "Average f1 score on test data:  0.622\n",
      "Std dev of f1 scores on test data:  0.006\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for churn.csv\n",
      "*********************************************\n",
      "shape:  (5000, 20)\n",
      "\n",
      "Average f1 score on training data:  0.644\n",
      "Average f1 score on test data:  0.546\n",
      "Std dev of f1 scores on test data:  0.022\n",
      "\n",
      "Average f1 score on training data:  0.696\n",
      "Average f1 score on test data:  0.553\n",
      "Std dev of f1 scores on test data:  0.018\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for biomed.csv\n",
      "*********************************************\n",
      "shape:  (209, 254)\n",
      "\n",
      "Average f1 score on training data:  0.897\n",
      "Average f1 score on test data:  0.8\n",
      "Std dev of f1 scores on test data:  0.1\n",
      "\n",
      "Average f1 score on training data:  0.988\n",
      "Average f1 score on test data:  0.913\n",
      "Std dev of f1 scores on test data:  0.03\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for kdd_el_nino-small.csv\n",
      "*********************************************\n",
      "shape:  (782, 746)\n",
      "\n",
      "Average f1 score on training data:  0.978\n",
      "Average f1 score on test data:  0.501\n",
      "Std dev of f1 scores on test data:  0.207\n",
      "\n",
      "Average f1 score on training data:  0.917\n",
      "Average f1 score on test data:  0.349\n",
      "Std dev of f1 scores on test data:  0.117\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for artificial-characters.csv\n",
      "*********************************************\n",
      "shape:  (10218, 7)\n",
      "\n",
      "Average f1 score on training data:  0.75\n",
      "Average f1 score on test data:  0.646\n",
      "Std dev of f1 scores on test data:  0.008\n",
      "\n",
      "Average f1 score on training data:  0.894\n",
      "Average f1 score on test data:  0.778\n",
      "Std dev of f1 scores on test data:  0.006\n",
      "\n",
      "\n",
      "*********************************************\n",
      "Calling for fri_c3_500_25.csv\n",
      "*********************************************\n",
      "shape:  (500, 25)\n",
      "\n",
      "Average f1 score on training data:  0.787\n",
      "Average f1 score on test data:  0.667\n",
      "Std dev of f1 scores on test data:  0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average f1 score on training data:  0.908\n",
      "Average f1 score on test data:  0.793\n",
      "Std dev of f1 scores on test data:  0.038\n"
     ]
    }
   ],
   "source": [
    "test_public_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fffbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c03028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', 'd'], dtype='<U1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.array(['a','b','a','b','c','d','a'])\n",
    "u = np.unique(n)\n",
    "u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
